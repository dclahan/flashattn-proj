=== Attention Mechanism Benchmark ===
Configuration: B=8, nh=8, N=64, d=64
Total Q size: 1 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 51.857 ms
  Max: 52.844 ms
  Avg: 52.673 ms
Flash Attention:
  Min: 2.910 ms
  Max: 2.988 ms
  Avg: 2.951 ms

Avg Speedup: 17.85x



=== Attention Mechanism Benchmark ===
Configuration: B=16, nh=8, N=64, d=64
Total Q size: 2 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 153.504 ms
  Max: 154.135 ms
  Avg: 153.879 ms
Flash Attention:
  Min: 4.508 ms
  Max: 5.266 ms
  Avg: 4.630 ms

Avg Speedup: 33.23x




=== Attention Mechanism Benchmark ===
Configuration: B=32, nh=8, N=64, d=64
Total Q size: 4 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 510.019 ms
  Max: 510.700 ms
  Avg: 510.386 ms
Flash Attention:
  Min: 7.525 ms
  Max: 8.824 ms
  Avg: 7.830 ms

Avg Speedup: 65.18x




=== Attention Mechanism Benchmark ===
Configuration: B=8, nh=12, N=64, d=64
Total Q size: 1.5 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 98.249 ms
  Max: 98.741 ms
  Avg: 98.593 ms
Flash Attention:
  Min: 3.967 ms
  Max: 4.493 ms
  Avg: 4.205 ms

Avg Speedup: 23.45x




=== Attention Mechanism Benchmark ===
Configuration: B=16, nh=12, N=64, d=64
Total Q size: 3 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 310.911 ms
  Max: 311.486 ms
  Avg: 311.276 ms
Flash Attention:
  Min: 6.061 ms
  Max: 6.852 ms
  Avg: 6.226 ms

Avg Speedup: 50.00x




=== Attention Mechanism Benchmark ===
Configuration: B=32, nh=12, N=64, d=64
Total Q size: 6 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 1126.003 ms
  Max: 1127.725 ms
  Avg: 1126.938 ms
Flash Attention:
  Min: 10.574 ms
  Max: 12.550 ms
  Avg: 11.312 ms

Avg Speedup: 99.62x



=== Attention Mechanism Benchmark ===
Configuration: B=8, nh=16, N=64, d=64
Total Q size: 2 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 153.682 ms
  Max: 154.202 ms
  Avg: 153.997 ms
Flash Attention:
  Min: 4.519 ms
  Max: 5.207 ms
  Avg: 4.641 ms

Avg Speedup: 33.18x



=== Attention Mechanism Benchmark ===
Configuration: B=16, nh=16, N=64, d=64
Total Q size: 4 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 510.311 ms
  Max: 511.038 ms
  Avg: 510.676 ms
Flash Attention:
  Min: 7.553 ms
  Max: 8.823 ms
  Avg: 7.864 ms

Avg Speedup: 64.94x




=== Attention Mechanism Benchmark ===
Configuration: B=32, nh=16, N=64, d=64
Total Q size: 8 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 2163.832 ms
  Max: 2170.191 ms
  Avg: 2166.793 ms
Flash Attention:
  Min: 13.689 ms
  Max: 17.324 ms
  Avg: 15.308 ms

Avg Speedup: 141.55x



=== Attention Mechanism Benchmark ===
Configuration: B=8, nh=12, N=128, d=64
Total Q size: 3 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 310.863 ms
  Max: 311.549 ms
  Avg: 311.331 ms
Flash Attention:
  Min: 7.332 ms
  Max: 8.315 ms
  Avg: 7.766 ms

Avg Speedup: 40.09x



=== Attention Mechanism Benchmark ===
Configuration: B=16, nh=12, N=128, d=64
Total Q size: 6 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 1126.288 ms
  Max: 1127.701 ms
  Avg: 1127.080 ms
Flash Attention:
  Min: 11.648 ms
  Max: 13.230 ms
  Avg: 12.253 ms

Avg Speedup: 91.98x


=== Attention Mechanism Benchmark ===
Configuration: B=8, nh=8, N=256, d=64
Total Q size: 4 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 510.173 ms
  Max: 511.165 ms
  Avg: 510.735 ms
Flash Attention:
  Min: 15.288 ms
  Max: 16.147 ms
  Avg: 15.587 ms

Avg Speedup: 32.77x


=== Attention Mechanism Benchmark ===
Configuration: B=16, nh=8, N=256, d=64
Total Q size: 8 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 2162.575 ms
  Max: 2168.453 ms
  Avg: 2165.595 ms
Flash Attention:
  Min: 28.441 ms
  Max: 31.002 ms
  Avg: 29.114 ms

Avg Speedup: 74.38x



=== Attention Mechanism Benchmark ===
Configuration: B=8, nh=12, N=256, d=64
Total Q size: 6 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 1126.539 ms
  Max: 1127.568 ms
  Avg: 1127.009 ms
Flash Attention:
  Min: 24.771 ms
  Max: 26.737 ms
  Avg: 25.541 ms

Avg Speedup: 44.13x



=== Attention Mechanism Benchmark ===
Configuration: B=8, nh=16, N=256, d=64
Total Q size: 8 MB

Warming up...
Benchmarking Naive Attention...
..........
Benchmarking Flash Attention...
..........

=== RESULTS ===
Naive Attention:
  Min: 2162.645 ms
  Max: 2168.607 ms
  Avg: 2165.579 ms
Flash Attention:
  Min: 28.390 ms
  Max: 30.615 ms
  Avg: 29.076 ms

Avg Speedup: 74.48x


Configuration: B=8, nh=8, N=64, d=64
Configuration: B=16, nh=8, N=64, d=64
Configuration: B=32, nh=8, N=64, d=64

Configuration: B=8, nh=12, N=64, d=64
Configuration: B=16, nh=12, N=64, d=64
Configuration: B=32, nh=12, N=64, d=64

Configuration: B=8, nh=16, N=64, d=64
Configuration: B=16, nh=16, N=64, d=64
Configuration: B=32, nh=16, N=64, d=64

Configuration: B=8, nh=12, N=128, d=64
Configuration: B=16, nh=12, N=128, d=64

Configuration: B=8, nh=8, N=256, d=64
Configuration: B=8, nh=12, N=256, d=64
Configuration: B=8, nh=16, N=256, d=64
Configuration: B=16, nh=8, N=256, d=64